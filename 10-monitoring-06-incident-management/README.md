# Домашнее задание к занятию "10.06. Инцидент-менеджмент"

## Задание 

> Составьте постмортем, на основе реального сбоя системы Github в 2018 году.
> 
> Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).


### Краткое описание инцидента

21 октября 2018 года, в 22:52  UTC несколько сервисов GitHub пострадали от нарушения связности сети и последующих проблем в работе БД. В результате множество пользователей наблюдали устаревшую или неполную информацию на сайте GitHub.com. 

### Предшествующие события

Плановые работы по техобслуживанию сети для замены 100-гигабитного оптического оборудования.

### Причина инцидента

Настройка репликатора MySQL `orchestrator` без учёта инфратруктуры.  Началом инцидента послужила потеря связности между сетевым концентратором и основным датацентром на восточном побережье США. В результате которых развалились кластеры БД.

### Воздействие

На протяжении 24 часов и 11 минут 100% пользователей испытывали проблемы при работе с сайтом: не работали Issues, Webhooks, невозможно было создать и разместить страницы на GitHub Pages, на сайте отображалась устаревшая или неполная информация.

### Обнаружение

В 22:54 внутренние системы мониторинга начали генерировать оповещения, указывающие на многочисленные сбои. В 23:02 дежурные инженеры определили, что множество кластеров баз данных находились в неожиданном состоянии.

### Реакция

Дежурные инженеры вручную остановили деплой и перевели систему в статус "желтый". 

Это действие автоматически перевело ситуацию в активный инцидент и отправило предупреждение координатору инцидента. Он изменил статус сервиса на "красный".

Подключили дополнительных инженеров из команды администрирования БД.

Отключили часть сервисов для пользователей, чтобы снизить нагрузку на кластер и обезопасить систему от дальнейшей потери пользовательских данных.
### Восстановление

Инженеры разработали план по восстановлению:восстановиться из резервных копий, синхронизировать реплики на обоих сайтах, вернуться к стабильной топологии обслуживания, а затем возобновить обработку заданий в очереди. 

В середине следующего рабочего дня, когда нагрузка на сервис стала пиковой, были развёрнуты дополнительные кластеры БД.

На последнем этапе были возвращены в работу отключенные сервисы, и скопившиеся задачи по вызову веб-хуков и публикации GitHub Pages начали выполняться.

### Таймлайн

* 2018 October 21 22:52 UTC: Потеря сетевого взаимодействия, развалился кластер БД
* 2018 October 21 22:54 UTC: Внутренняя система мониторинга оповещает инженеров о многочисленных ошибках
* 2018 October 21 23:02 UTC: Множество кластеров БД оказались в "неожиданном" состоянии
* 2018 October 21 23:07 UTC: Остановка деплоя
* 2018 October 21 23:09 UTC: Команда перевера сайт в "желтый". Отправлено предупреждение координатору инцидента
* 2018 October 21 23:11 UTC: Координатор подключился к команде, спустя две минуты изменил статус на "красный"
* 2018 October 21 23:13 UTC: Подключили дополнительных инженеров из команды обслуживания БД
* 2018 October 21 23:19 UTC: Инженеры остановили работу веб-хуков и сборку GitHub Pages чтобы не подвергать данные пользователей дальнейшей опасности
* 2018 October 22 00:05 UTC: Инженеры начали разработку плана начали разработку плана по устранению несоответствий данных и реализации наших процедур аварийного переключения для MySQL
* 2018 October 22 00:41 UTC: Начался процесс восстановления из бекапа, параллельно инженеры искали способы ускорить передачу данных
* 2018 October 22 06:51 UTC: Несколько кластеров завершили восстановление из бекапов в датацентре на восточном побережье и начали репликацию данных с датацентра на западном побережье
* 2018 October 22 07:46 UTC: GutHub опубликовал сообщение в блоге, чтобы предоставить пользователям больше информации. 
* 2018 October 22 11:12 UTC: Восстановился основной кластер БД на восточном побережье. При этом множество read-only баз продолжали  репликацию, отставая от мастера на несколько часов.
* 2018 October 22 13:15 UTC: Зафиксирован пик нагрузки трафика на GitHub.com. Принято решение развернуть дополнительные реплики MySQL на чтение.
* 2018 October 22 16:24 UTC: Реплики синхронизированы. Возврат к исходной топологии
* 2018 October 22 16:45 UTC: Начало обработки накопившегося стека событий
* 2018 October 22 23:03 UTC: Все ожидающие сборки веб-перехватчиков и страниц были обработаны, а целостность и правильная работа всех систем подтверждены. Статус сайта изменился на "зеленый"  
### Последующие действия

- В процессе восстановления, были собраны несколько журналов MySQL с данными, которые не были реплицированы на западное побережье. Их не очень много. Проводится анализ чтобы определить, сколько их них получится восстановить автоматически, а какие потребуют взаимодействия с пользователями
- Настроить конфигурацию Orchestrator, чтобы предотвратить передачу primary роли между регионами- Переработать систему статусов: отображать различные компоненты платформы, чтобы пользователи знали статус каждой службы..
- За несколько недель до инцидента, запустили инициативу по улучшению отказоустойчивости сетевого трафика.Этот инцидент добавил срочности этой инициативе.
- Компания займёт более проактивную позицию в тестировании собственных предположений.
- Компания начнёт систематическую практику проверки сценариев неудач до того, как они смогут оказать влияние на сервис. Ивестиции в chaos engineering.